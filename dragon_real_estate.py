# -*- coding: utf-8 -*-
"""dragon real estate.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1w-2bIDMSRX1IjXRXpqID5_bAU4DLxw2W
"""

import pandas as pd
import numpy as np

housing=pd.read_csv("data.csv")
housing.head()

housing.info()

housing.isnull().sum()

##housing.dropna(inplace=True)
housing.fillna(housing['RM'].mean(),inplace=True)

housing.isnull().sum()

housing.describe()

housing.dtypes

import matplotlib.pyplot as plt

housing.hist(bins=50,figsize=(20,15))
plt.show()

## train test splitting
from sklearn.model_selection import train_test_split
train_set,test_set=train_test_split(housing,test_size=0.2,random_state=42)
print(f"rows in the train_set :{len(train_set)}")
print(f"rows in the test_set: {len(test_set)}")

from sklearn.model_selection import StratifiedShuffleSplit
split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)
for train_index, test_index in split.split(housing, housing['CHAS']):
    strat_train_set = housing.loc[train_index]
    strat_test_set = housing.loc[test_index]

housing = strat_train_set.copy()
housing.head()

## looking for  correlation
#correaltion means the realationship between the variable
corr_matrix=housing.corr()
#print(corr_matrix)
## im taking # MEDV columns
print(corr_matrix['MEDV'].sort_values(ascending=False))
## this is called pearson correaltion
## pearson correalation states that if constantly increase on value the other value is constanstly decreasing
## +1 means there is a strong postive correaltion and -1 means there is negative correlation

### scatter plot
plt.scatter(x=housing['RM'],y=housing['MEDV'])
plt.show()



import seaborn as sns
sns.pairplot(housing)

## trying  different atributes

housing['TAX_RM']=housing['TAX']/housing['RM']
housing.head()

## now we will see the correaltion how it is corresponding
corr_matrix=housing.corr()
##corr_matrix.sort_values('MEDV',ascending=False)
print(corr_matrix['MEDV'].sort_values(ascending=False))

## let the plot
plt.scatter(y=housing['MEDV'],x=housing['TAX_RM'])
plt.show()

## scikit-learn design
## estimator  it estimate some parameter imputer it has fit method and transforms the data set
## transformer takes input and return output based on learning from fit()
##predictor liner regression model is an example of predictor. fit() and predict() are the common function

## feature scaling
## Min-max scaling(normalization) lies between 0 to 1
## standardization  sklearn provide StandardScaler for this

housing = strat_train_set.drop("MEDV", axis=1)
housing_labels = strat_train_set["MEDV"].copy()

from sklearn.impute import SimpleImputer
imputer = SimpleImputer(strategy="median")
imputer.fit(housing)
X = imputer.transform(housing)
housing_tr = pd.DataFrame(X, columns=housing.columns)

## create the pip line
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.preprocessing import StandardScaler
my_pipeline=Pipeline([('imputer',SimpleImputer(strategy='mean')),('std_scaler',StandardScaler())])

my_pipeline_tr=my_pipeline.fit_transform(housing)
my_pipeline_tr

my_pipeline_tr.shape



## selecting the desired the model for dragon real estates
from sklearn.linear_model import LinearRegression
from  sklearn .tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
model=RandomForestRegressor()
#model=DecisionTreeRegressor()
#model=LinearRegression()
model.fit(my_pipeline_tr,housing_labels)

some_data=housing.iloc[:5]
some_labels=housing_labels.iloc[:5]
#print(some_data)
#print(some_labels)
prepared_data=my_pipeline.transform(some_data)
model.predict(prepared_data)
#list(some_labels)

list(some_labels)

## evaluation of the model

### sklearn metric
from sklearn.metrics import mean_squared_error
housing_prediction=model.predict(my_pipeline_tr)
rmse=mean_squared_error(housing_labels,housing_prediction)
rmsle=np.sqrt(rmse)
rmsle
## here the data model is over fit in decision tree regressor

## using better evaluation technique
## cross validation
from sklearn.model_selection import cross_val_score
scores=cross_val_score(model,my_pipeline_tr,housing_labels,scoring='neg_mean_squared_error',cv=10)
rmse_scores=np.sqrt(-scores)
rmse_scores

def print_scores(scores):
  print("scores is :",scores)
  print("mean",scores.mean())
  print("standard deviation",scores.std())

print(print_scores(rmse_scores))

## testing the model

X_test=strat_test_set.drop('MEDV',axis=1)
Y_test=strat_test_set['MEDV'].copy()
x_test_prepared=my_pipeline.transform(X_test)
final_prediction=model.predict(x_test_prepared)
final_mse=mean_squared_error(final_prediction,Y_test)
final_rmse=np.sqrt(final_mse)
print(final_rmse)